{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weightUpdateUsingNN_FL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 679,
      "metadata": {
        "id": "mlVduUyTgpW8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.datasets import load_digits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only for Mac OS\n",
        "import os \n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True' "
      ],
      "metadata": {
        "id": "KwgM3NFKy_x2"
      },
      "execution_count": 680,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading dataset\n",
        "digits = load_digits()\n",
        "X1, y1 = load_digits(return_X_y=True)\n",
        "\n",
        "# creating Index from 0 to # of points in X1\n",
        "ind_arr = np.arange(0,X1.shape[0])\n",
        "print (ind_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxxvfyrnwLif",
        "outputId": "356f3f9d-17e7-4031-f73b-3e9f42878ab7"
      },
      "execution_count": 681,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    1    2 ... 1794 1795 1796]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(ind_arr)\n",
        "print (ind_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEJ3yo3Ywenl",
        "outputId": "2284c546-ce27-4a44-b1c6-b2ad35194701"
      },
      "execution_count": 682,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1433 1648 1380 ... 1708 1479  631]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshuffled original data\n",
        "X = X1[ind_arr]\n",
        "y = y1[ind_arr]"
      ],
      "metadata": {
        "id": "ca6j3cVFwhvj"
      },
      "execution_count": 683,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ind_digits will store all index of class 0, 1, ... , 9 \n",
        "ind_digits = []\n",
        "\n",
        "for i in range(10) :\n",
        "  _, ind_i = np.where([y==i])\n",
        "  ind_digits.append(ind_i)"
      ],
      "metadata": {
        "id": "jYUvFK2Yw1zq"
      },
      "execution_count": 684,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Central data Preparation "
      ],
      "metadata": {
        "id": "_toOzOED0cy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial 30% data samples to central \n",
        "n_pts = int((X1.shape[0]*.3)/10)\n",
        "print(n_pts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wshCLNQnw_Ep",
        "outputId": "ec60c05f-4b7b-4305-ef7c-f416bc40f538"
      },
      "execution_count": 685,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_list = []\n",
        "\n",
        "for i in range(10) :\n",
        "  ind = ind_digits[i][0:n_pts]\n",
        "  dummy_list.extend(ind)  # extend so that 1D [ind[0], ind[1],...] array not like this [[ind]]\n",
        "\n",
        "X_central = X[dummy_list]\n",
        "y_central = y[dummy_list]"
      ],
      "metadata": {
        "id": "Yw2ER_LvxMye"
      },
      "execution_count": 686,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_central))\n",
        "print(X_central.shape)\n",
        "\n",
        "print(type(y_central))\n",
        "print(y_central.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neSIgHYTxOqS",
        "outputId": "fff791a1-abdb-4c18-9df1-9104e1c9e28d"
      },
      "execution_count": 687,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(530, 64)\n",
            "<class 'numpy.ndarray'>\n",
            "(530,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_central.shape)\n",
        "print(y_central.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGXzAmppxbVu",
        "outputId": "91c76e39-f11b-4cde-a6c6-066edea99d8f"
      },
      "execution_count": 688,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(530, 64)\n",
            "(530,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 30% data ==> 66% training 33% testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_central_train, X_central_test, y_central_train, y_central_test = train_test_split(X_central, y_central, test_size=0.33)"
      ],
      "metadata": {
        "id": "Tk5g2faV3wCm"
      },
      "execution_count": 689,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_central_train.shape)\n",
        "print(X_central_test.shape)\n",
        "print(y_central_train.shape)\n",
        "print(y_central_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqscbMVt5Jrk",
        "outputId": "3716ec08-14b6-47d8-faed-1a34c971e190"
      },
      "execution_count": 690,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(355, 64)\n",
            "(175, 64)\n",
            "(355,)\n",
            "(175,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "# one-hot encoding of output\n",
        "y_central_train = np_utils.to_categorical(y_central_train,10)\n",
        "y_central_test = np_utils.to_categorical(y_central_test,10)\n",
        "\n",
        "print(X_central_test.shape)\n",
        "print(y_central_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyl7vIwwhK23",
        "outputId": "f47d7609-caf8-4a41-8601-1c1fd4fbb73a"
      },
      "execution_count": 691,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(175, 64)\n",
            "(175, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers, Model, regularizers\n",
        "from tensorflow.keras import optimizers"
      ],
      "metadata": {
        "id": "-7zL20YehXUx"
      },
      "execution_count": 692,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Input() is used to instantiate a Keras tensor.\n",
        "\n",
        "A Keras tensor is a symbolic tensor-like object, which we augment with certain attributes that allow us to build a Keras model just by knowing the inputs and outputs of the model.\n",
        "\n",
        "For instance, if a, b and c are Keras tensors, it becomes possible to do: model = Model(input=[a, b], output=c)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "l1 = layers.Input(shape=(64,))"
      ],
      "metadata": {
        "id": "E0GmC9IYhbfK"
      },
      "execution_count": 693,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dense implements the operation: output = activation(dot(input, kernel) + bias) \n",
        "where activation is the element-wise activation function passed as the activation argument, \n",
        "      kernel is a weights matrix created by the layer, and \n",
        "      bias is a bias vector created by the layer (only applicable if use_bias is True). These are all attributes of Dense.\n",
        "\"\"\"\n",
        "l2 = layers.Dense(15, activation='sigmoid')(l1)"
      ],
      "metadata": {
        "id": "b4ZVPVBahn0w"
      },
      "execution_count": 694,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = layers.Dense(10, activation='softmax')(l2)"
      ],
      "metadata": {
        "id": "d2-06nQkhuf1"
      },
      "execution_count": 695,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(l1, output)"
      ],
      "metadata": {
        "id": "Tdqk-qAXhxFP"
      },
      "execution_count": 696,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndxB07_uh1Mu",
        "outputId": "71e7418d-1190-4629-d7d6-69c20380d85e"
      },
      "execution_count": 697,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_20 (InputLayer)       [(None, 64)]              0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 15)                975       \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 10)                160       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,135\n",
            "Trainable params: 1,135\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# regularization helps the neural network converge properly.\n",
        "# Ridge regression adds “squared magnitude” of coefficient as penalty term to the loss function\n",
        "l2_rate = 1e-4\n",
        "for layer in model.layers:\n",
        "    if hasattr(layer, 'kernel_regularizer'):\n",
        "        layer.kernel_regularizer = regularizers.l2(l2_rate)\n",
        "        layer.bias_regularizer = regularizers.l2(l2_rate)\n",
        "        layer.activity_regularizer = regularizers.l2(l2_rate)"
      ],
      "metadata": {
        "id": "9JHcvl1li6Io"
      },
      "execution_count": 698,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(learning_rate=0.1, momentum=0.9), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dgUtD3DgiFw4"
      },
      "execution_count": 699,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_central_train, y=y_central_train, validation_data=(X_central_test,y_central_test), batch_size=100, epochs=100)\n",
        "weights_central = model.get_weights()\n",
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0N1L0TNjETb",
        "outputId": "de156147-2b84-498a-8803-eb0b668e1b4f"
      },
      "execution_count": 700,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 60ms/step - loss: 2.5657 - accuracy: 0.1127 - val_loss: 2.2892 - val_accuracy: 0.1714\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.2439 - accuracy: 0.1662 - val_loss: 2.1859 - val_accuracy: 0.2229\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1252 - accuracy: 0.2704 - val_loss: 2.0001 - val_accuracy: 0.2914\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9466 - accuracy: 0.3437 - val_loss: 1.8432 - val_accuracy: 0.3714\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7448 - accuracy: 0.4423 - val_loss: 1.7147 - val_accuracy: 0.4743\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5816 - accuracy: 0.5577 - val_loss: 1.5640 - val_accuracy: 0.5771\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4292 - accuracy: 0.6254 - val_loss: 1.4286 - val_accuracy: 0.6000\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.2893 - accuracy: 0.6761 - val_loss: 1.3376 - val_accuracy: 0.6343\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1629 - accuracy: 0.7296 - val_loss: 1.2094 - val_accuracy: 0.6457\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0736 - accuracy: 0.7634 - val_loss: 1.1117 - val_accuracy: 0.7143\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9748 - accuracy: 0.8000 - val_loss: 1.0612 - val_accuracy: 0.6971\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.8487 - accuracy: 0.8197 - val_loss: 0.9264 - val_accuracy: 0.7314\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7836 - accuracy: 0.8282 - val_loss: 0.8977 - val_accuracy: 0.7086\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7096 - accuracy: 0.8338 - val_loss: 0.7820 - val_accuracy: 0.7886\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6486 - accuracy: 0.8423 - val_loss: 0.7270 - val_accuracy: 0.7771\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5930 - accuracy: 0.8648 - val_loss: 0.7056 - val_accuracy: 0.8000\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5579 - accuracy: 0.8620 - val_loss: 0.6384 - val_accuracy: 0.8286\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5158 - accuracy: 0.8648 - val_loss: 0.6423 - val_accuracy: 0.8286\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4875 - accuracy: 0.8958 - val_loss: 0.6251 - val_accuracy: 0.8286\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4541 - accuracy: 0.9042 - val_loss: 0.5701 - val_accuracy: 0.8343\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4263 - accuracy: 0.8986 - val_loss: 0.5036 - val_accuracy: 0.8457\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.8704 - val_loss: 0.5155 - val_accuracy: 0.8343\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3843 - accuracy: 0.8873 - val_loss: 0.4922 - val_accuracy: 0.8857\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3522 - accuracy: 0.9380 - val_loss: 0.4776 - val_accuracy: 0.8800\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3239 - accuracy: 0.9324 - val_loss: 0.4854 - val_accuracy: 0.8686\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3081 - accuracy: 0.9493 - val_loss: 0.4384 - val_accuracy: 0.8629\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2947 - accuracy: 0.9606 - val_loss: 0.4408 - val_accuracy: 0.8800\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2768 - accuracy: 0.9549 - val_loss: 0.4291 - val_accuracy: 0.8857\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2648 - accuracy: 0.9606 - val_loss: 0.4062 - val_accuracy: 0.8971\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2422 - accuracy: 0.9662 - val_loss: 0.4181 - val_accuracy: 0.8800\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2326 - accuracy: 0.9662 - val_loss: 0.4166 - val_accuracy: 0.8857\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2208 - accuracy: 0.9775 - val_loss: 0.3882 - val_accuracy: 0.8857\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2091 - accuracy: 0.9746 - val_loss: 0.3973 - val_accuracy: 0.8800\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1971 - accuracy: 0.9831 - val_loss: 0.3618 - val_accuracy: 0.8686\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1828 - accuracy: 0.9859 - val_loss: 0.3378 - val_accuracy: 0.8800\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1767 - accuracy: 0.9746 - val_loss: 0.3494 - val_accuracy: 0.8914\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1647 - accuracy: 0.9803 - val_loss: 0.3370 - val_accuracy: 0.9029\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1577 - accuracy: 0.9831 - val_loss: 0.3398 - val_accuracy: 0.9029\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1508 - accuracy: 0.9859 - val_loss: 0.3230 - val_accuracy: 0.9086\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1455 - accuracy: 0.9887 - val_loss: 0.3291 - val_accuracy: 0.8971\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1386 - accuracy: 0.9859 - val_loss: 0.3322 - val_accuracy: 0.8971\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1357 - accuracy: 0.9831 - val_loss: 0.3128 - val_accuracy: 0.8971\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1271 - accuracy: 0.9831 - val_loss: 0.2948 - val_accuracy: 0.8914\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1234 - accuracy: 0.9831 - val_loss: 0.3081 - val_accuracy: 0.8914\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1180 - accuracy: 0.9831 - val_loss: 0.3109 - val_accuracy: 0.8857\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1145 - accuracy: 0.9831 - val_loss: 0.2994 - val_accuracy: 0.8914\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1110 - accuracy: 0.9831 - val_loss: 0.2981 - val_accuracy: 0.8971\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1073 - accuracy: 0.9831 - val_loss: 0.3039 - val_accuracy: 0.8857\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1049 - accuracy: 0.9831 - val_loss: 0.3007 - val_accuracy: 0.8857\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1021 - accuracy: 0.9831 - val_loss: 0.2992 - val_accuracy: 0.8914\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0999 - accuracy: 0.9831 - val_loss: 0.3052 - val_accuracy: 0.8914\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0977 - accuracy: 0.9831 - val_loss: 0.2981 - val_accuracy: 0.8857\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0950 - accuracy: 0.9831 - val_loss: 0.2928 - val_accuracy: 0.8971\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0934 - accuracy: 0.9831 - val_loss: 0.2960 - val_accuracy: 0.8914\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0905 - accuracy: 0.9831 - val_loss: 0.2989 - val_accuracy: 0.8914\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0898 - accuracy: 0.9831 - val_loss: 0.2922 - val_accuracy: 0.8857\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0869 - accuracy: 0.9831 - val_loss: 0.2913 - val_accuracy: 0.8971\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0846 - accuracy: 0.9831 - val_loss: 0.2956 - val_accuracy: 0.8800\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0827 - accuracy: 0.9859 - val_loss: 0.2965 - val_accuracy: 0.8857\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0805 - accuracy: 0.9859 - val_loss: 0.2911 - val_accuracy: 0.8857\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0790 - accuracy: 0.9859 - val_loss: 0.2878 - val_accuracy: 0.8914\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0775 - accuracy: 0.9859 - val_loss: 0.2921 - val_accuracy: 0.8914\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0758 - accuracy: 0.9887 - val_loss: 0.3009 - val_accuracy: 0.8914\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0750 - accuracy: 0.9915 - val_loss: 0.2974 - val_accuracy: 0.8914\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0737 - accuracy: 0.9887 - val_loss: 0.2909 - val_accuracy: 0.8914\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0724 - accuracy: 0.9915 - val_loss: 0.2885 - val_accuracy: 0.8914\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0711 - accuracy: 0.9887 - val_loss: 0.2933 - val_accuracy: 0.8971\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0699 - accuracy: 0.9915 - val_loss: 0.2880 - val_accuracy: 0.8914\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0689 - accuracy: 0.9915 - val_loss: 0.2891 - val_accuracy: 0.8914\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0678 - accuracy: 0.9915 - val_loss: 0.2916 - val_accuracy: 0.8971\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0668 - accuracy: 0.9915 - val_loss: 0.2871 - val_accuracy: 0.8914\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0657 - accuracy: 0.9915 - val_loss: 0.2846 - val_accuracy: 0.8914\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0649 - accuracy: 0.9915 - val_loss: 0.2904 - val_accuracy: 0.8971\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9944 - val_loss: 0.2841 - val_accuracy: 0.8971\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0618 - accuracy: 0.9944 - val_loss: 0.2809 - val_accuracy: 0.9029\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0602 - accuracy: 0.9944 - val_loss: 0.2776 - val_accuracy: 0.9029\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0593 - accuracy: 0.9944 - val_loss: 0.2789 - val_accuracy: 0.9029\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0585 - accuracy: 0.9944 - val_loss: 0.2775 - val_accuracy: 0.8971\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0577 - accuracy: 0.9944 - val_loss: 0.2781 - val_accuracy: 0.8971\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0568 - accuracy: 0.9944 - val_loss: 0.2807 - val_accuracy: 0.8914\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0562 - accuracy: 0.9944 - val_loss: 0.2845 - val_accuracy: 0.8857\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0549 - accuracy: 0.9944 - val_loss: 0.2883 - val_accuracy: 0.8914\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8914\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.8914\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.8914\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.8914\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.8914\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.8914\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.8914\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.8914\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.8914\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.8914\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.8857\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.8914\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8914\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8857\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.8857\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8857\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.8857\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.8857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding out the type and shape of weights\n",
        "print(type(weights_central))\n",
        "print(len(weights_central))\n",
        "print(len(weights_central[0]))\n",
        "print(len(weights_central[0][0]))\n",
        "print(len(weights_central[1]))\n",
        "print(len(weights_central[2]))\n",
        "print(len(weights_central[2][0]))\n",
        "print(len(weights_central[3]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOwcYA2Rj01L",
        "outputId": "4ee396c6-8c8f-4f11-c3cc-d97e3964cfad"
      },
      "execution_count": 701,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "4\n",
            "64\n",
            "15\n",
            "15\n",
            "15\n",
            "10\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create digitwise local data sets"
      ],
      "metadata": {
        "id": "FcxIYTd283Hk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ-IrD8-6ikc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5be43fc-65b4-448f-d0de-12ca24c91d22"
      },
      "source": [
        "local_Xy = []\n",
        "\n",
        "for i in range(10) :\n",
        "\n",
        "  ind_i = ind_digits[i][n_pts:]\n",
        "  # print(ind_i)\n",
        "  local_X = X[ind_i]\n",
        "  local_y = y[ind_i]\n",
        "\n",
        "  print (local_X.shape, local_y.shape)\n",
        "  local_Xy.append((local_X,local_y))"
      ],
      "execution_count": 702,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(125, 64) (125,)\n",
            "(129, 64) (129,)\n",
            "(124, 64) (124,)\n",
            "(130, 64) (130,)\n",
            "(128, 64) (128,)\n",
            "(129, 64) (129,)\n",
            "(128, 64) (128,)\n",
            "(126, 64) (126,)\n",
            "(121, 64) (121,)\n",
            "(127, 64) (127,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "wuMvWiit_8ZD"
      },
      "execution_count": 703,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l0_weights = np.zeros((64, 15), dtype=\"float32\")\n",
        "l1_weights = np.zeros((15,), dtype=\"float32\")\n",
        "l2_weights = np.zeros((15, 10), dtype=\"float32\")\n",
        "l3_weights = np.zeros((10,), dtype=\"float32\")\n",
        "\n",
        "for i in range(10) :\n",
        "  # loading the model \n",
        "  model = load_model('model.h5')\n",
        "\n",
        "  local_X, local_y = local_Xy[i]\n",
        "  local_y = np_utils.to_categorical(local_y,10)\n",
        "\n",
        "  model.fit(x=local_X, y=local_y, batch_size=100, epochs=100, verbose=0)\n",
        "  temp_Wei = model.get_weights()\n",
        "\n",
        "  # just to easy the calculation part\n",
        "  l0_w = np.array(temp_Wei[0])\n",
        "  l1_w = np.array(temp_Wei[1])\n",
        "  l2_w = np.array(temp_Wei[2])\n",
        "  l3_w = np.array(temp_Wei[3])\n",
        "  \n",
        "  l0_weights +=  l0_w\n",
        "  l1_weights +=  l1_w\n",
        "  l2_weights +=  l2_w\n",
        "  l3_weights +=  l3_w\n",
        "  "
      ],
      "metadata": {
        "id": "wS2HpGx59dSh"
      },
      "execution_count": 704,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DOING MEAN CAL"
      ],
      "metadata": {
        "id": "kvBNwbDDVKIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before calulation weights\n",
        "\n",
        "print(l1_weights)\n",
        "print(l1_weights)\n",
        "print(l1_weights)\n",
        "print(l1_weights)\n",
        "\n",
        "updated_l0_w = l0_weights/10\n",
        "updated_l1_w = l1_weights/10\n",
        "updated_l2_w = l2_weights/10\n",
        "updated_l3_w = l3_weights/10\n",
        "\n",
        "# After Calculation weights\n",
        "\n",
        "print(updated_l0_w)\n",
        "print(updated_l1_w)\n",
        "print(updated_l2_w)\n",
        "print(updated_l3_w)\n"
      ],
      "metadata": {
        "id": "vJDAgG_4VNYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e30f33-d092-494c-a63a-32bdb77b7a79"
      },
      "execution_count": 705,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.03600358 -0.00883649  0.05985445  0.11704143 -0.0909074  -0.1785597\n",
            " -0.01107405 -0.40473926 -0.17898825 -0.02861921 -0.06610353 -0.04890189\n",
            "  0.12401389 -0.03953564 -0.00688897]\n",
            "[ 0.03600358 -0.00883649  0.05985445  0.11704143 -0.0909074  -0.1785597\n",
            " -0.01107405 -0.40473926 -0.17898825 -0.02861921 -0.06610353 -0.04890189\n",
            "  0.12401389 -0.03953564 -0.00688897]\n",
            "[ 0.03600358 -0.00883649  0.05985445  0.11704143 -0.0909074  -0.1785597\n",
            " -0.01107405 -0.40473926 -0.17898825 -0.02861921 -0.06610353 -0.04890189\n",
            "  0.12401389 -0.03953564 -0.00688897]\n",
            "[ 0.03600358 -0.00883649  0.05985445  0.11704143 -0.0909074  -0.1785597\n",
            " -0.01107405 -0.40473926 -0.17898825 -0.02861921 -0.06610353 -0.04890189\n",
            "  0.12401389 -0.03953564 -0.00688897]\n",
            "[[-1.21327862e-01  1.06535807e-01  1.99790373e-01 -1.97086662e-01\n",
            "   2.33314365e-01 -9.24959127e-03 -2.31294304e-01 -1.98105931e-01\n",
            "  -1.16617847e-02  1.51852414e-01 -2.12092906e-01  2.55177051e-01\n",
            "   4.70163263e-02 -9.72089916e-02 -8.75048041e-02]\n",
            " [-2.73319446e-02  1.04489312e-01  2.38280799e-02  1.69355020e-01\n",
            "  -2.34443754e-01  7.30171278e-02  2.57976443e-01 -7.63729289e-02\n",
            "   1.36911616e-01  2.44526178e-01  2.14665025e-01  1.51337400e-01\n",
            "   1.01909623e-01 -3.37514915e-02 -2.81651355e-02]\n",
            " [ 1.54255852e-01  1.98919803e-01  2.97869053e-02  2.37899229e-01\n",
            "   1.32245645e-02  3.77144711e-03  2.52322257e-01 -3.69683713e-01\n",
            "  -3.44556034e-01  7.33304173e-02  8.19714926e-03 -9.64909643e-02\n",
            "   1.76588386e-01  1.21924561e-02  2.83970058e-01]\n",
            " [-1.92732122e-02 -9.02821645e-02  1.50125682e-01  1.19563423e-01\n",
            "  -2.46930882e-01 -1.31485686e-01  1.49384722e-01 -2.52802074e-01\n",
            "  -2.76935130e-01  3.66073191e-01 -2.37794314e-02 -2.35421538e-01\n",
            "   2.93341964e-01  6.99565336e-02  3.84511769e-01]\n",
            " [ 2.45334536e-01 -2.87743509e-02  1.34114772e-01 -2.24358603e-01\n",
            "  -3.90438177e-02 -4.99332011e-01 -1.01360820e-01 -3.80846649e-01\n",
            "  -3.90124530e-01  5.97112402e-02  5.28236985e-01 -3.79326753e-02\n",
            "   1.02028593e-01 -2.50794709e-01  2.44270161e-01]\n",
            " [ 1.59353003e-01  2.38056391e-01  1.53661326e-01 -4.34545904e-01\n",
            "  -3.55866961e-02 -9.38045233e-02  3.95399392e-01  1.56989247e-01\n",
            "  -7.17922091e-01  6.66290939e-01 -1.35880709e-01 -1.55612156e-01\n",
            "   1.05051078e-01  2.27904320e-01  1.34457629e-02]\n",
            " [ 9.37533826e-02  2.23160654e-01  1.35967523e-01  3.18266302e-01\n",
            "   1.95007063e-02 -5.97059205e-02  1.06733635e-01  6.96721300e-02\n",
            "  -1.86000153e-01  1.31377280e-01 -1.34150669e-01  2.15588376e-01\n",
            "  -1.88289478e-01  4.75081690e-02  2.93942451e-01]\n",
            " [-1.25448316e-01  1.35377571e-01  1.81807026e-01  4.21910957e-02\n",
            "   3.99308763e-02  6.53460100e-02 -2.87854791e-01 -1.98938996e-01\n",
            "  -2.37794489e-01  1.23818144e-01 -1.02986872e-01  1.61537454e-01\n",
            "   2.52638280e-01 -1.29716277e-01  7.16004074e-02]\n",
            " [ 2.54237443e-01 -3.47325169e-02 -1.93279535e-01 -7.73901790e-02\n",
            "   1.66775376e-01 -1.05606958e-01  2.42049932e-01  1.44421339e-01\n",
            "   1.89590499e-01 -1.48462862e-01  1.25584081e-01 -1.05276510e-01\n",
            "   1.25091318e-02 -2.22380683e-01  1.88118532e-01]\n",
            " [-1.71509117e-01 -1.82603747e-02 -1.96265146e-01  1.35909647e-01\n",
            "   3.34995724e-02  1.27079979e-01  1.70852676e-01 -2.20218629e-01\n",
            "  -3.12535316e-01  1.60257369e-01  1.11776188e-01 -2.78250754e-01\n",
            "  -2.20030159e-01 -1.99403718e-01 -1.17826119e-01]\n",
            " [ 2.07601622e-01 -3.23131710e-01  2.42895991e-01  2.71353632e-01\n",
            "   1.31626874e-01 -3.99837494e-01  1.83378369e-01 -4.14015353e-01\n",
            "  -3.18665832e-01 -2.73434967e-01  4.30337667e-01 -2.86224067e-01\n",
            "   2.24486321e-01 -1.75608732e-02  2.83152759e-01]\n",
            " [-1.11534752e-01  8.53023399e-03  3.09889942e-01  2.67405838e-01\n",
            "  -8.16627890e-02 -6.88334927e-02 -8.89874622e-02 -4.01517570e-01\n",
            "  -3.88560504e-01 -1.47278488e-01  4.89801705e-01 -2.57120524e-02\n",
            "  -4.19711098e-02 -1.28653441e-02  3.62184584e-01]\n",
            " [ 2.34563351e-01  2.04177529e-01  6.75033778e-03  4.65294033e-01\n",
            "  -2.61418074e-01  1.42704949e-01 -1.40865073e-01 -2.28902493e-02\n",
            "  -6.16678059e-01  3.10535252e-01  2.99413264e-01  3.34087014e-02\n",
            "   4.55223620e-02 -1.56717882e-01  1.73335403e-01]\n",
            " [ 5.88371456e-02 -2.66265720e-01 -1.00004159e-01  3.19463670e-01\n",
            "  -6.74133450e-02 -3.11518461e-01  3.35390866e-01  1.96958616e-01\n",
            "  -2.22237036e-01  7.39881516e-01  1.64919168e-01 -1.52829975e-01\n",
            "   2.34651729e-01  1.69973284e-01  1.11612536e-01]\n",
            " [-1.02386668e-01 -1.88777059e-01 -1.62590697e-01  7.66104460e-02\n",
            "  -1.57431602e-01  1.46946326e-01  3.40726115e-02 -7.75433630e-02\n",
            "  -9.85641927e-02 -2.92603727e-02  2.48269841e-01  9.91692692e-02\n",
            "  -1.88722044e-01 -1.18346669e-01  1.68013945e-01]\n",
            " [-2.43436337e-01  2.41820648e-01 -2.30661780e-01 -5.10879830e-02\n",
            "   7.02779368e-02  1.68858081e-01  2.12740898e-01 -2.61900008e-01\n",
            "   2.01751534e-02  4.79968227e-02  2.28880242e-01 -7.36027211e-02\n",
            "  -1.43202826e-01  3.25727239e-02  1.09145120e-01]\n",
            " [ 3.10406424e-02 -1.31771816e-02  2.20752031e-01  2.28422016e-01\n",
            "  -1.35169134e-01 -2.19316762e-02 -5.40567636e-02  1.96573332e-01\n",
            "  -1.48869172e-01 -1.58172660e-02  1.64775513e-02  1.97165534e-01\n",
            "  -7.38028437e-02 -1.74761653e-01 -4.02496234e-02]\n",
            " [-9.19083357e-02 -6.51242137e-02 -2.07845613e-01  1.88225001e-01\n",
            "  -2.75309831e-01  2.43625909e-01  2.41790622e-01  2.47650016e-02\n",
            "  -3.08483660e-01 -3.63802426e-02 -8.23959988e-03 -2.18006924e-01\n",
            "   2.46028990e-01 -7.69864246e-02  1.72261998e-01]\n",
            " [ 1.02247939e-01 -2.03537829e-02  2.21962601e-01  1.20777868e-01\n",
            "   1.44692808e-01  7.44579583e-02 -3.18390870e-04  5.09836316e-01\n",
            "   4.71004099e-01 -4.43644524e-01  4.74893272e-01 -1.23837389e-01\n",
            "   3.18709224e-01  3.22619855e-01 -1.93443730e-01]\n",
            " [-6.59430772e-02 -3.96011770e-02  2.28143737e-01  2.28618175e-01\n",
            "  -2.92899042e-01 -1.21797517e-01 -7.96300694e-02  1.47960797e-01\n",
            "   4.48731333e-01  1.83421552e-01 -2.67837852e-01  3.47662121e-02\n",
            "   5.20619750e-02  3.95535767e-01 -2.86295265e-01]\n",
            " [ 1.47871628e-01 -4.77309644e-01  1.80964589e-01  3.40524167e-02\n",
            "  -2.48966128e-01  4.42897044e-02  3.05939287e-01  9.98582318e-02\n",
            "   2.38709420e-01 -1.12533472e-01  2.18073770e-01  4.11310762e-01\n",
            "   2.66519815e-01 -5.70867419e-01 -1.23214886e-01]\n",
            " [-1.24209747e-01 -7.86200941e-01  2.05028765e-02  3.41323316e-01\n",
            "  -1.48068392e-03 -9.45767090e-02  1.95254147e-01 -3.41126502e-01\n",
            "   6.66868865e-01 -5.41293859e-01  9.94205773e-01  1.31800145e-01\n",
            "   2.60510743e-01  1.59654051e-01 -1.18287370e-01]\n",
            " [ 1.26181124e-02 -2.09154874e-01 -1.09668389e-01 -6.78648651e-02\n",
            "   1.53021097e-01  1.72334403e-01 -3.06512594e-01 -9.58023369e-02\n",
            "  -6.04127869e-02 -6.20528534e-02  2.58839786e-01  3.94334763e-01\n",
            "  -1.90846711e-01  9.10071358e-02 -1.51266187e-01]\n",
            " [-2.54685163e-01 -1.43002674e-01  4.15666960e-02  2.35497504e-01\n",
            "  -1.63636923e-01  1.47437468e-01  9.99988094e-02  1.66350335e-01\n",
            "   2.34326869e-01  2.59175360e-01  1.96865290e-01 -1.72164470e-01\n",
            "  -1.94255173e-01 -4.25367467e-02 -2.69133031e-01]\n",
            " [-4.86814824e-04 -7.54591078e-02 -2.42896825e-01 -4.48040292e-02\n",
            "   1.63222343e-01  1.60634860e-01  2.90920921e-02 -1.98177740e-01\n",
            "   7.66800046e-02 -7.23279896e-04 -2.53877584e-02 -1.75838917e-01\n",
            "   2.10724801e-01 -6.69631213e-02  1.30723447e-01]\n",
            " [-9.40845311e-02  4.91829783e-01  6.51344284e-02  5.50790802e-02\n",
            "  -1.53284043e-01 -3.17065604e-02 -2.22636331e-02 -3.66822809e-01\n",
            "  -6.20470829e-02 -1.06431603e-01 -4.96004164e-01 -1.90721303e-01\n",
            "  -2.28806168e-01  2.65801251e-01  4.18324083e-01]\n",
            " [ 2.57035613e-01  6.12630472e-02 -4.35270276e-03 -3.91947180e-01\n",
            "   8.68221298e-02 -3.39317143e-01  3.81056130e-01 -3.39284509e-01\n",
            "   6.21918976e-01 -2.42907077e-01 -6.53833389e-01  2.16864586e-01\n",
            "  -3.26670259e-02  1.79388791e-01  9.38957781e-02]\n",
            " [ 2.27524161e-01 -1.69797108e-01 -8.37032646e-02 -5.17575979e-01\n",
            "  -2.68394470e-01 -2.54282296e-01  5.61596096e-01  5.67782810e-03\n",
            "   4.54239428e-01  2.29057714e-01 -4.98079300e-01  5.09586558e-02\n",
            "  -7.48268887e-02  2.56983519e-01 -3.29315178e-02]\n",
            " [-1.02820754e-01 -5.38761020e-01  3.21729392e-01 -5.85228801e-01\n",
            "  -3.41789991e-01 -2.59959310e-01  5.66978872e-01 -2.54664719e-01\n",
            "   1.67414621e-01  1.24566093e-01  1.04918972e-01  6.26396313e-02\n",
            "   1.78634927e-01 -4.64501768e-01 -1.18569866e-01]\n",
            " [ 2.43615940e-01  2.31102735e-01 -1.48197562e-01  2.56379694e-01\n",
            "  -2.10534379e-01  1.31412491e-01 -3.15106362e-01 -8.14737305e-02\n",
            "   3.94323289e-01 -4.08678241e-02  2.45626550e-02  2.71983773e-01\n",
            "   2.46225238e-01  4.92967553e-02 -1.47135228e-01]\n",
            " [-1.32094875e-01  3.29353422e-01 -7.18142241e-02  6.98409200e-01\n",
            "  -8.95832628e-02  2.39348680e-01 -3.22110236e-01 -6.56413674e-01\n",
            "  -2.81657785e-01 -8.97640139e-02  2.99972564e-01  4.28181827e-01\n",
            "  -4.23984043e-02  6.20466694e-02 -1.04009129e-01]\n",
            " [-2.58555382e-01 -2.64025956e-01  7.76231810e-02  1.59461722e-01\n",
            "  -1.98396906e-01 -1.18396267e-01  2.50179201e-01 -1.30082041e-01\n",
            "   2.44174093e-01  1.99511856e-01 -2.16513544e-01  7.96492025e-02\n",
            "  -2.31994838e-01 -1.51685283e-01 -1.21712886e-01]\n",
            " [-2.58828938e-01 -1.93939924e-01 -2.14818627e-01  2.43520290e-01\n",
            "   1.86863080e-01  1.24780938e-01  2.18371242e-01  1.56292692e-01\n",
            "   5.64689115e-02 -2.15350360e-01 -2.37029821e-01 -2.53033899e-02\n",
            "   2.04416960e-01  3.64641286e-02  2.04273671e-01]\n",
            " [ 2.31892377e-01  6.50159240e-01  1.44888580e-01  4.13403288e-02\n",
            "   2.18955994e-01 -2.11162001e-01 -3.92987072e-01 -2.83114314e-01\n",
            "  -3.10956180e-01 -1.77984163e-01 -2.61365801e-01 -7.64364600e-02\n",
            "   1.96660027e-01 -6.12884089e-02 -6.48841411e-02]\n",
            " [-1.21317375e-02  3.46139997e-01  1.09816410e-01  1.48939952e-01\n",
            "   1.48306459e-01 -1.17708042e-01 -4.42967415e-01 -4.94438499e-01\n",
            "   3.99155468e-02  7.73274899e-02 -3.24102938e-01  6.41628206e-02\n",
            "   3.12560111e-01  2.90981710e-01  5.37786298e-02]\n",
            " [ 1.63246356e-02 -3.87623042e-01  1.04884088e-01  1.99125156e-01\n",
            "  -2.13113233e-01 -3.88148576e-01  2.90620625e-01  2.02030942e-01\n",
            "   3.55430067e-01  1.38072118e-01  1.34131327e-01 -3.54103372e-02\n",
            "  -2.04081237e-02  2.45284408e-01 -3.51615369e-01]\n",
            " [-1.24960877e-01 -1.46560788e-01  2.30256408e-01 -3.29422653e-01\n",
            "  -9.70127359e-02 -4.83828366e-01  2.08945587e-01  6.39669299e-01\n",
            "  -2.70934463e-01  3.56934577e-01 -4.27720159e-01  2.95461744e-01\n",
            "   2.78101981e-01 -4.00474608e-01 -9.33894992e-01]\n",
            " [ 2.55609509e-02  5.10585785e-01  2.10321516e-01 -2.07251720e-02\n",
            "  -3.47724557e-01  1.28056458e-03 -4.61848408e-01 -3.14210474e-01\n",
            "  -2.42902085e-01  3.78404528e-01 -7.86782563e-01  3.86100113e-01\n",
            "  -1.97497174e-01 -1.82298303e-01 -6.17431030e-02]\n",
            " [-6.93538561e-02  2.55459636e-01 -7.83041865e-02  1.08383156e-01\n",
            "   2.40389660e-01 -8.06286931e-02 -3.64908993e-01 -5.29307961e-01\n",
            "  -1.40270859e-01 -2.27562308e-01 -7.97669813e-02  1.93829343e-01\n",
            "   2.09575981e-01  1.06448000e-02  1.75493032e-01]\n",
            " [ 1.82313576e-01 -3.15160155e-02 -2.93849967e-02 -2.30457217e-01\n",
            "   1.04637638e-01  3.02356146e-02  1.04423866e-01 -1.78951010e-01\n",
            "  -2.54242867e-01 -2.84490664e-03 -2.60768145e-01 -2.25229815e-01\n",
            "  -2.20132619e-01  8.02760050e-02 -2.23143965e-01]\n",
            " [ 6.05944172e-02 -1.32190004e-01 -6.30673096e-02  3.54005843e-02\n",
            "   1.56347290e-01 -1.54827312e-01  1.22917369e-01 -2.50665247e-01\n",
            "  -2.04402372e-01  4.00841497e-02 -2.13205367e-01 -5.41952029e-02\n",
            "  -5.17589599e-03 -2.41981596e-01 -7.34622926e-02]\n",
            " [-1.07996106e-01  1.88154340e-01 -4.15102169e-02  1.11614205e-01\n",
            "  -1.50884777e-01 -2.11512476e-01 -5.08784413e-01 -5.23972869e-01\n",
            "   2.20929891e-01 -2.55024254e-01 -2.24659324e-01  3.62541944e-01\n",
            "  -1.00090846e-01  1.26053423e-01 -3.76387268e-01]\n",
            " [ 1.09593652e-01  7.81367272e-02 -2.10081294e-01 -1.44002214e-01\n",
            "   8.54636133e-02  1.19594082e-01 -2.40498021e-01  8.10443878e-01\n",
            "  -1.78506285e-01 -1.11339882e-01  5.07326350e-02 -2.72428215e-01\n",
            "  -2.29024906e-02  2.61729956e-01 -7.29459405e-01]\n",
            " [ 3.92262712e-02  1.08185515e-01  9.96068399e-03  4.23215061e-01\n",
            "  -2.93020666e-01 -3.93126220e-01 -2.59298742e-01  4.42722254e-02\n",
            "   6.25262707e-02 -7.18002915e-02 -4.71632302e-01  5.38832128e-01\n",
            "  -8.01010132e-02  3.12468201e-01 -7.34461069e-01]\n",
            " [-3.18506397e-02  1.54275045e-01  1.53485924e-01 -4.05760229e-01\n",
            "  -1.83556788e-02 -4.72652651e-02 -1.05317712e-01 -1.82972386e-01\n",
            "   1.77342743e-01  9.19815451e-02 -1.35900229e-01  2.47830078e-01\n",
            "   1.29473060e-01 -1.83920190e-01 -2.86434114e-01]\n",
            " [ 2.57898688e-01 -3.88428457e-02 -4.02078731e-03 -1.97801128e-01\n",
            "   8.69146660e-02 -1.03658453e-01  4.50529009e-02 -3.96735370e-01\n",
            "   5.97686358e-02 -1.57261848e-01  4.06946272e-01 -9.49776843e-02\n",
            "   3.06775510e-01  2.72015899e-01  5.46100847e-02]\n",
            " [-2.15620160e-01  2.19113827e-01  1.14835165e-01 -3.12781185e-01\n",
            "  -1.43425971e-01 -1.01889715e-01 -5.69859445e-02 -9.00588334e-01\n",
            "   3.47106546e-01  1.66312102e-02 -3.95443738e-02 -2.42128089e-01\n",
            "  -1.39356583e-01  1.23568252e-01  3.27735364e-01]\n",
            " [-2.00565189e-01  2.49214053e-01 -1.67275771e-01 -7.84978345e-02\n",
            "  -1.63856611e-01 -4.29581944e-03  4.90148440e-02 -1.17065333e-01\n",
            "  -4.60759923e-02  2.22161323e-01  1.15535883e-02  4.06847969e-02\n",
            "  -1.41554847e-01  1.92158028e-01  9.79172364e-02]\n",
            " [-9.60093588e-02  8.91384631e-02  2.61372179e-01 -1.49497569e-01\n",
            "   4.63375356e-03  1.98304549e-01  2.44154222e-02  2.22972661e-01\n",
            "  -1.53224589e-02  2.10045621e-01 -2.04193875e-01  2.56322831e-01\n",
            "  -7.00514391e-02  2.50067532e-01  5.47711179e-02]\n",
            " [ 3.73333395e-02 -3.77599299e-02 -2.52102315e-01  3.20421532e-02\n",
            "   1.98935151e-01  2.01465219e-01  2.21696168e-01 -5.38197100e-01\n",
            "   1.60304636e-01 -1.90715715e-01  8.04231912e-02  1.17451116e-01\n",
            "   2.25425750e-01 -1.98589772e-01 -1.04441285e-01]\n",
            " [ 2.47479871e-01 -5.38421683e-02 -9.26407576e-02 -1.48775131e-01\n",
            "   5.80932200e-02  6.89089373e-02 -1.18801996e-01  3.26789558e-01\n",
            "  -3.67606640e-01 -1.85555462e-02  2.68683434e-01 -3.52324694e-01\n",
            "   3.11983645e-01  1.83035895e-01 -3.76726165e-02]\n",
            " [ 1.76144928e-01  1.66311607e-01  2.26797670e-01  7.88292885e-01\n",
            "  -2.28872627e-01 -2.22503275e-01 -3.07219386e-01  1.58148795e-01\n",
            "  -4.24940675e-01 -4.01688227e-03 -5.33262976e-02 -9.51205119e-02\n",
            "   4.21801239e-01 -3.25199306e-01 -4.22826946e-01]\n",
            " [-2.62713172e-02 -3.75490934e-01  7.42753316e-03 -2.01333120e-01\n",
            "  -1.43970191e-01 -3.91905993e-01  4.11116779e-01  5.43389544e-02\n",
            "  -6.93718046e-02 -1.76725343e-01 -3.09315026e-01 -1.81272272e-02\n",
            "  -7.86474496e-02 -3.32126915e-01  4.60110039e-01]\n",
            " [-2.30264381e-01 -3.68329525e-01 -1.07003450e-01 -5.06380610e-02\n",
            "  -2.59795189e-01 -2.89665796e-02  1.64016932e-01  6.51721120e-01\n",
            "   2.33290821e-01  1.54142734e-02  3.43465000e-01 -5.99005878e-01\n",
            "   1.60685882e-01  8.28700140e-02  2.04968810e-01]\n",
            " [-1.09034076e-01 -1.09773472e-01 -7.95938745e-02  1.20983481e-01\n",
            "  -2.61532376e-03  5.25134727e-02 -6.69107065e-02 -2.06961595e-02\n",
            "   2.64631808e-02 -2.69419141e-02 -1.10526547e-01 -2.36434609e-01\n",
            "   7.23272115e-02 -2.03692436e-01 -2.83464730e-01]\n",
            " [-2.15247363e-01 -2.42310882e-01  2.10653335e-01 -1.47368640e-01\n",
            "  -1.98397450e-02 -2.27478534e-01  8.35876167e-02 -1.22972980e-01\n",
            "  -6.63701147e-02  7.99401999e-02  1.35132402e-01  1.23161055e-01\n",
            "   8.19868445e-02 -3.39780748e-01 -1.30242541e-01]\n",
            " [-5.52932872e-03 -3.84110585e-02 -1.63858160e-01  1.86624601e-01\n",
            "   1.94175959e-01  2.13861972e-01  3.63485143e-02 -1.87641099e-01\n",
            "  -4.35756743e-02  1.93197817e-01 -2.56773472e-01 -8.86001587e-02\n",
            "  -2.55543143e-01 -1.14782467e-01 -1.47031978e-01]\n",
            " [-1.34202719e-01 -7.87715018e-02 -1.80349335e-01 -1.56360984e-01\n",
            "   2.42124081e-01  7.11725280e-02  2.21441627e-01 -6.58365637e-02\n",
            "  -2.78595060e-01  2.12272644e-01  1.71655387e-01  1.71030000e-01\n",
            "  -1.35377783e-03  1.61223784e-01  3.24601904e-02]\n",
            " [ 1.07803881e-01  2.36284167e-01  8.68631378e-02  2.53405809e-01\n",
            "   1.89857371e-02  1.91463485e-01  2.49833629e-01 -4.24344152e-01\n",
            "  -5.41224301e-01 -1.15463078e-01 -3.40473801e-01 -3.08262795e-01\n",
            "   1.95015922e-01 -4.83728833e-02  3.19230139e-01]\n",
            " [ 2.49943376e-01  5.23199141e-02 -1.79798976e-01  3.26550812e-01\n",
            "  -7.40158558e-02  4.53719236e-02  2.20096678e-01  5.31834848e-02\n",
            "  -5.88704228e-01  6.19610175e-02  9.62425619e-02 -4.99544144e-01\n",
            "   8.85016620e-02  6.87866285e-03 -6.64885268e-02]\n",
            " [-3.82516906e-02 -2.08699256e-01  1.82078391e-01 -5.04204333e-01\n",
            "  -1.87460214e-01 -2.47421652e-01  3.72627318e-01  4.09243643e-01\n",
            "   2.53119707e-01 -1.45259097e-01  4.56966788e-01 -5.35178304e-01\n",
            "   1.16427485e-02  1.96337894e-01  4.03518267e-02]\n",
            " [ 2.52424240e-01 -4.25816625e-01  1.84664965e-01 -5.38454764e-02\n",
            "   6.82505593e-02 -4.19234097e-01  2.33083323e-01  5.58432460e-01\n",
            "   7.73338825e-02 -1.14551798e-01 -7.67674148e-02 -3.84417772e-01\n",
            "   1.36469811e-01 -1.12517022e-01  1.52258664e-01]\n",
            " [ 7.84721822e-02 -4.21958528e-02  1.99270576e-01  4.00100082e-01\n",
            "   8.59654173e-02  2.14867860e-01 -1.38639137e-01  5.64770997e-01\n",
            "  -2.18509585e-01 -3.47431362e-01  1.67175442e-01 -3.34526807e-01\n",
            "   1.91223845e-01 -2.69662440e-01 -1.02164552e-01]\n",
            " [ 2.14674473e-01 -9.76044834e-02 -1.22402832e-01  1.77884668e-01\n",
            "  -7.51975086e-03 -1.13250509e-01  1.54173613e-01  4.87202734e-01\n",
            "  -1.43929690e-01  1.64644763e-01 -2.59455740e-01 -8.66366103e-02\n",
            "   7.93512538e-02 -2.03644946e-01 -1.23371586e-01]]\n",
            "[ 0.00360036 -0.00088365  0.00598544  0.01170414 -0.00909074 -0.01785597\n",
            " -0.0011074  -0.04047393 -0.01789882 -0.00286192 -0.00661035 -0.00489019\n",
            "  0.01240139 -0.00395356 -0.0006889 ]\n",
            "[[ 0.0095129   0.5420549   0.15956357 -0.20079009  0.4956231  -0.26791272\n",
            "   0.02746111  0.42267418 -0.06449066  0.06519295]\n",
            " [ 1.5514584  -1.3508117  -1.7996542  -1.9045632   1.0869825   2.4153047\n",
            "   2.1089625   1.2520027  -1.9056642  -2.3950794 ]\n",
            " [-0.37081787 -0.11589714  0.14038852  0.10824418  0.5191337   0.5306953\n",
            "  -0.21354179  0.43765682 -0.08148539 -0.23141284]\n",
            " [ 2.1296203  -1.3920515   2.7959294  -2.0131996  -0.00559231 -1.1580709\n",
            "  -0.7684712   1.814956   -1.1669604  -0.50154924]\n",
            " [ 0.16731843  0.24828911  0.3496347   0.09334568 -0.2383302  -0.1747138\n",
            "   0.11515691 -0.48927253  0.08480646 -0.44418877]\n",
            " [ 0.1592226  -0.04462662  0.2665101   0.2542918   0.10906921 -0.17498219\n",
            "  -0.05413855  0.08484704 -0.1419339   0.3288383 ]\n",
            " [-2.571616    1.9195884   0.42085066  1.0763742  -1.0319      1.6301851\n",
            "  -2.2878916  -1.0920726   1.06521     1.0637624 ]\n",
            " [-1.0256896   2.0071826   3.0036845  -0.00399827 -2.043676   -1.8682516\n",
            "   3.061623   -0.92096794  0.79245526 -2.939686  ]\n",
            " [-0.16686037  1.1754446  -2.2281947  -1.4923954   2.2540293  -0.35220855\n",
            "   0.9210836  -2.418698    0.90298283  2.4452195 ]\n",
            " [-1.0658568   1.3691355  -0.8418164   1.5298527  -1.0251837   0.45109028\n",
            "  -0.1621706   1.6484066   0.5406796  -0.9208171 ]\n",
            " [ 1.714668   -2.9062266   1.1617893   2.0962005  -1.5569927  -1.7687709\n",
            "  -1.2762079  -0.18297338  2.3406208   1.0904452 ]\n",
            " [-1.131365    0.9007193  -0.4450871  -0.3551797   2.4087372  -1.6463842\n",
            "  -1.4849715   2.293467   -1.3546594   0.37333125]\n",
            " [-0.09185608  0.21582195 -0.4355101   0.3103965  -0.01256691 -0.18361194\n",
            "   0.1022712  -0.24489248 -0.18077834  0.19481376]\n",
            " [ 0.53555304 -0.84218216 -1.062176   -1.9274395   0.03480637  0.64686286\n",
            "   0.9272418  -0.20224571  1.7870228   0.07538833]\n",
            " [ 1.7640152  -1.0658946  -0.12260355  2.6910205  -1.5467283   1.6557028\n",
            "  -1.0780818  -1.5752083  -2.7285419   2.2030344 ]]\n",
            "[-0.29116398  0.13630708 -0.15605481  0.1137854   0.2669251   0.11178817\n",
            "  0.15712643  0.0321001  -0.27254137 -0.09827174]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Updating Central Server"
      ],
      "metadata": {
        "id": "aqS7GCZbWBFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creation of appropriate weights datatype\n",
        "list0 = updated_l0_w.tolist()\n",
        "list1 = updated_l1_w.tolist()\n",
        "list2 = updated_l2_w.tolist()\n",
        "list3 = updated_l3_w.tolist()\n",
        "\n",
        "updated_Weights_Consolidated = []\n",
        "updated_Weights_Consolidated.append(updated_l0_w)\n",
        "updated_Weights_Consolidated.append(updated_l1_w)\n",
        "updated_Weights_Consolidated.append(updated_l2_w)\n",
        "updated_Weights_Consolidated.append(updated_l3_w)"
      ],
      "metadata": {
        "id": "GVbQHhtGduvl"
      },
      "execution_count": 706,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(updated_Weights_Consolidated)\n",
        "# print(weights_central)\n",
        "\n",
        "# Updating the weights to the central server \n",
        "model.set_weights(updated_Weights_Consolidated)"
      ],
      "metadata": {
        "id": "E82Cci6OckK7"
      },
      "execution_count": 707,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_central_train, y=y_central_train, validation_data=(X_central_test,y_central_test), batch_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs5JbF1MZYkh",
        "outputId": "5c84e30b-801a-48ed-c6f2-6f386ef312d4"
      },
      "execution_count": 708,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 66ms/step - loss: 0.5590 - accuracy: 0.8225 - val_loss: 1.1223 - val_accuracy: 0.6571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f404a1a7690>"
            ]
          },
          "metadata": {},
          "execution_count": 708
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_central_test)\n",
        "print(predictions[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ngtu0oYjKVq",
        "outputId": "ac0ff62e-aff3-4587-ce15-77bc758caad0"
      },
      "execution_count": 709,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.9525932e-04 3.3795668e-03 4.3948996e-05 3.6484073e-06 9.0027843e-03\n",
            " 1.7237983e-03 9.8324609e-01 1.1511470e-04 1.6531672e-03 3.6669633e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_prediction(index):\n",
        "    print('predicted probabilities:')\n",
        "    print(predictions[index])\n",
        "    print('predicted category', np.argmax(predictions[index]))\n",
        "    print('true probabilities:')\n",
        "    print(y_central_test[index])\n",
        "    print('true category', np.argmax(y_central_test[index]))\n",
        "    img = X_central_test[index].reshape(8,8)\n",
        "    plt.imshow(img)"
      ],
      "metadata": {
        "id": "N610z88Njf62"
      },
      "execution_count": 710,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction(9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "IRZTX7QyjhOv",
        "outputId": "9011aa00-6198-46b9-baf4-3b34a0c1df00"
      },
      "execution_count": 711,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted probabilities:\n",
            "[9.4522012e-04 3.3970925e-03 7.7213816e-05 6.0443308e-06 6.7959735e-03\n",
            " 2.2361979e-03 9.8458660e-01 2.2701720e-04 1.7017127e-03 2.6954678e-05]\n",
            "predicted category 6\n",
            "true probabilities:\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "true category 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}